# 人才简历智能筛选与管理系统 - 项目需求分析文档

## 一、项目概述

### 1.1 项目背景

构建一个轻量级、高性能的智能化人才简历筛选与管理平台，实现对简历的自动化解析、智能筛选、信息提取、向量化存储与多维度查询分析。

### 1.2 目标用户

* **HR / 招聘人员**: 日常简历筛选、人才库管理

* **人才管理部门**: 人才数据分析、招聘决策支持

* **校园招聘团队**: 批量简历处理、快速筛选

### 1.3 技术栈约束

| 技术组件      | 版本要求   | 用途          |
| --------- | ------ | ----------- |
| Python    | 3.13+  | 核心开发语言      |
| LangChain | 1.2+   | LLM 应用框架    |
| LangGraph | 1.0+   | 工作流编排       |
| FastAPI   | 0.120+ | Web API 框架  |
| Streamlit | 1.30+  | 前端界面        |
| MinIO     | Latest | 对象存储（图片/文件） |
| MySQL     | 8.0+   | 关系型数据库      |
| Redis     | 5.0+   | 缓存/任务队列     |
| ChromaDB  | Latest | 向量数据库       |
| uv        | Latest | 依赖管理工具      |

**重要约束**:

* **禁止使用** `langchain_classic` 包内容

* 使用最新的 LangChain API 和最佳实践

* Embedding 服务使用 **DashScope Embedding API**

### 1.4 环境配置

```env
# DashScope API 配置
DASHSCOPE_API_KEY="sk-c80deedf0c634601917ced9a32c79e50"
DASHSCOPE_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1"

# DeepSeek API 配置
DS_API_KEY="sk-b269fc61a4734b60a3e9c92100a39845"
DS_BASE_URL="https://api.deepseek.com"

# MinIO 配置
MINIO_ENDPOINT="39.108.222.138:9000"
MINIO_CONSOLE_URL="http://39.108.222.138:9001"
MINIO_ACCESS_KEY="root"
MINIO_SECRET_KEY="123456"
MINIO_BUCKET="resume-images"
MINIO_SECURE=false
# MySQL 配置
MYSQL_HOST="39.108.222.138"
MYSQL_PORT=3306
MYSQL_USER="root"
MYSQL_PASSWORD="123456"
MYSQL_DATABASE="resume_screening"
# Redis 配置
REDIS_HOST="39.108.222.138"
REDIS_PORT=6379
REDIS_PASSWORD="123456"
REDIS_DB=0
```

***

## 二、核心功能模块（100分）

### 2.1 筛选条件管理模块 (25分)

#### 2.1.1 功能需求

| 功能     | 分值  | 说明            |
| ------ | --- | ------------- |
| 新增筛选条件 | 5分  | 创建新的简历筛选条件配置  |
| 修改筛选条件 | 5分  | 编辑已有筛选条件      |
| 逻辑删除   | 5分  | 软删除机制         |
| 分页查询   | 10分 | 支持多状态、多条件组合查询 |

#### 2.1.2 数据模型

```python
# 筛选条件表 (screening_condition)
- id: UUID (主键)
- name: str (条件名称)
- description: str (条件描述)
- conditions: JSON (筛选条件配置)
  - skills: List[str] (技能要求)
  - education_level: str (学历要求)
  - experience_years: int (工作年限)
  - major: List[str] (专业要求)
  - school_tier: List[str] (院校层次)
- status: Enum (active/inactive/deleted)
- created_at: datetime
- updated_at: datetime
```

#### 2.1.3 API 设计

```
POST   /api/v1/conditions          # 新增筛选条件
PUT    /api/v1/conditions/{id}     # 修改筛选条件
DELETE /api/v1/conditions/{id}     # 逻辑删除
GET    /api/v1/conditions          # 分页查询（支持多状态、多条件）
```

***

### 2.2 简历解析与存储模块 (15分)

#### 2.2.1 功能需求

| 功能   | 分值  | 说明                       |
| ---- | --- | ------------------------ |
| 简历解析 | 10分 | 解析PDF/Word简历文件，提取文本与个人图片 |
| 图片存储 | 5分  | 图片存储至MinIO，地址关联人才信息表     |

#### 2.2.2 解析流程

```
上传PDF → 文本提取 → 图片提取 → MinIO存储 → 地址回写
```

#### 2.2.3 技术实现

* **PDF解析**: 使用 `pymupdf` 提取文本和图片

* **Word解析**: 使用 `python-docx` 提取文本和图片

* **图片存储**: MinIO Bucket `resume-images`

  * Endpoint: `39.108.222.138:9000`

  * Console: `http://39.108.222.138:9001`

* **文件命名**: `{talent_id}/photo_{timestamp}.jpg`

***

### 2.3 智能信息提取与入库模块 (20分)

#### 2.3.1 功能需求

| 功能      | 分值  | 说明                 |
| ------- | --- | ------------------ |
| 大模型条件筛选 | 5分  | 使用LLM判断候选人是否符合筛选条件 |
| 实体信息提取  | 5分  | 提取姓名、技能、院校、联系方式等   |
| 入库与查询   | 10分 | 数据持久化与多条件分页查询      |

#### 2.3.2 LangGraph 工作流设计

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  解析提取节点 │ -> │  筛选节点    │ -> │  入库节点    │ -> │  缓存节点    │
│(ParseExtract)│    │(FilterNode) │    │ (StoreNode) │    │ (CacheNode) │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
       │                  │                  │                  │
       ↓ (失败)           ↓ (失败)           ↓ (失败)           ↓ (失败)
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│   错误处理   │    │   错误处理   │    │   错误处理   │    │   错误处理   │
│(ErrorHandler)│    │(ErrorHandler)│    │(ErrorHandler)│    │(ErrorHandler)│
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
```

**工作流节点说明**:

* `ParseExtractNode`: 解析文档、提取文本和图片、LLM实体提取

* `FilterNode`: LLM条件筛选判断

* `StoreNode`: 数据入库MySQL、图片存储MinIO、向量存储ChromaDB

* `CacheNode`: 缓存结果至Redis

**工作流状态**:

* `pending`: 待处理

* `parsing`: 解析中

* `filtering`: 筛选中

* `storing`: 入库中

* `caching`: 缓存中

* `completed`: 完成

* `failed`: 失败

#### 2.3.3 实体提取 Schema

```python
class CandidateInfo(BaseModel):
    """候选人信息实体"""
    name: str = Field(description="姓名")
    phone: str | None = Field(description="联系电话")
    email: str | None = Field(description="电子邮箱")
    education_level: str = Field(description="学历")
    school: str = Field(description="毕业院校")
    major: str = Field(description="专业")
    graduation_date: str | None = Field(description="毕业日期")
    skills: list[str] = Field(description="技能列表")
    work_years: int | None = Field(description="工作年限")
```

#### 2.3.4 数据模型

```python
# 人才信息表 (talent_info)
- id: UUID (主键)
- name: str (姓名)
- phone: str (电话-加密)
- email: str (邮箱-加密)
- education_level: str (学历)
- school: str (毕业院校)
- major: str (专业)
- graduation_date: date (毕业日期)
- skills: JSON (技能列表)
- work_years: int (工作年限)
- photo_url: str (照片地址-MinIO)
- resume_text: Text (简历文本)
- condition_id: UUID (关联筛选条件)
- workflow_status: Enum (pending/parsing/filtering/storing/caching/completed/failed)
- screening_status: Enum (qualified/disqualified)
- screening_date: datetime (筛选日期)
- error_message: Text (错误信息)
- created_at: datetime
- updated_at: datetime
```

#### 2.3.5 API 设计

```
POST   /api/v1/talents/upload-screen  # 上传简历并执行智能筛选
GET    /api/v1/talents                # 分页查询人才列表（按姓名、专业、院校、选拔日期）
GET    /api/v1/talents/{id}           # 获取人才详情
```

**查询参数说明**:

* `name`: 姓名（模糊匹配）

* `major`: 专业

* `school`: 毕业院校

* `screening_date_start`: 选拔日期起始

* `screening_date_end`: 选拔日期结束

***

### 2.4 向量化存储模块 (20分)

#### 2.4.1 功能需求

| 功能   | 分值  | 说明                             |
| ---- | --- | ------------------------------ |
| 向量存储 | 20分 | 使用LangChain将人才信息向量化存储至ChromaDB |

#### 2.4.2 技术实现

* **Embedding模型**: DashScope Embedding API

  * API Key: `DASHSCOPE_API_KEY`

  * Base URL: `https://dashscope.aliyuncs.com/compatible-mode/v1`

* **向量数据库**: ChromaDB（本地持久化）

* **文档切分**: 按简历模块切分（教育、技能、经历）

#### 2.4.3 向量存储设计

```python
# ChromaDB Collection
collection_name = "talent_resumes"

# 文档结构
{
    "id": "talent_id",
    "embedding": List[float],
    "metadata": {
        "name": str,
        "school": str,
        "major": str,
        "education_level": str,
        "skills": List[str]
    },
    "document": str  # 简历文本
}
```

#### 2.4.4 API 设计

```
POST   /api/v1/talents/{id}/vectorize  # 向量化指定人才
POST   /api/v1/talents/batch-vectorize # 批量向量化
```

***

### 2.5 多维度数据分析与查询模块 (20分)

#### 2.5.1 功能需求

| 功能    | 分值  | 说明               |
| ----- | --- | ---------------- |
| RAG查询 | 20分 | 基于向量检索的智能问答与数据分析 |

#### 2.5.2 查询维度

* **按学校查询**: 统计不同院校的人才分布

* **按学历查询**: 本科/硕士/博士分布

* **按专业查询**: 专业领域人才统计

* **按技能查询**: 技能匹配度分析

#### 2.5.3 RAG 查询流程

```
用户问题 → 向量化 → ChromaDB检索 → 上下文构建 → LLM生成回答
```

#### 2.5.4 API 设计

```
POST   /api/v1/analysis/query          # RAG智能查询（支持按学校、学历、专业）
GET    /api/v1/analysis/statistics     # 统计数据
```

***

## 三、系统架构设计

### 3.1 整体架构

```
┌─────────────────────────────────────────────────────┐
│           Streamlit Frontend Layer                  │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐  │
│  │ 条件管理 │ │ 上传筛选 │ │ 人才查询 │ │ 数据分析 │  │
│  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘  │
└───────┼──────────┼──────────┼──────────┼──────────┘
        │          │          │          │
        └──────────┴──────────┴──────────┘
                          │ HTTP API
                          ↓
┌─────────────────────────────────────────────────────┐
│              FastAPI Layer (精简)                   │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐              │
│  │ 条件管理 │ │ 人才管理 │ │ 分析查询 │              │
│  └────┬────┘ └────┬────┘ └────┬────┘              │
└───────┼──────────┼──────────┼──────────────────────┘
        │          │          │
┌───────┼──────────┼──────────┼──────────────────────┐
│       │    LangGraph Workflow (4节点)              │
│  ┌────┴────┐ ┌────┴────┐ ┌────┴────┐ ┌────┴────┐ │
│  │解析提取  │ │  筛选   │ │  入库   │ │  缓存   │ │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘ │
└─────────────────────────────────────────────────────┘
        │          │          │
┌───────┼──────────┼──────────┼──────────────────────┐
│       │    Storage Layer                            │
│  ┌────┴────┐ ┌────┴────┐ ┌────┴────┐ ┌────┴────┐ │
│  │  MySQL   │ │  MinIO   │ │ChromaDB │ │  Redis  │ │
│  │ (云端)   │ │(云端存储)│ │ (向量)  │ │ (缓存)  │ │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘ │
└─────────────────────────────────────────────────────┘
```

### 3.2 目录结构

```
ResumeScreening/
├── src/
│   ├── api/                    # FastAPI 路由
│   │   ├── v1/
│   │   │   ├── conditions.py   # 筛选条件管理
│   │   │   ├── talents.py      # 人才管理（含上传、筛选、向量化）
│   │   │   └── analysis.py     # 数据分析查询
│   │   └── deps.py             # 依赖注入
│   ├── core/                   # 核心配置
│   │   ├── config.py           # 配置管理
│   │   ├── security.py         # 安全加密
│   │   ├── exceptions.py       # 异常处理
│   │   └── logger.py           # 日志配置(loguru)
│   ├── models/                 # ORM 数据库模型
│   │   ├── __init__.py
│   │   ├── condition.py        # 筛选条件模型
│   │   └── talent.py           # 人才信息模型
│   ├── schemas/                # Pydantic Schema
│   │   ├── __init__.py
│   │   ├── condition.py        # 筛选条件Schema
│   │   ├── talent.py           # 人才信息Schema
│   │   └── common.py           # 通用响应模型
│   ├── workflows/              # LangGraph 工作流
│   │   ├── __init__.py
│   │   ├── resume_workflow.py  # 简历处理工作流
│   │   ├── parse_extract_node.py
│   │   ├── filter_node.py
│   │   ├── store_node.py
│   │   └── cache_node.py
│   ├── parsers/                # 解析器
│   │   ├── __init__.py
│   │   └── document_parser.py  # 文档解析器（支持PDF/Word）
│   ├── storage/                # 存储客户端
│   │   ├── __init__.py
│   │   ├── minio_client.py
│   │   ├── chroma_client.py
│   │   └── redis_client.py
│   └── utils/                  # 工具函数
│       ├── __init__.py
│       └── encryption.py       # AES加密工具
├── frontend/                   # Streamlit 前端
│   ├── app.py                  # 主应用入口
│   ├── pages/                  # 页面模块
│   │   ├── conditions.py       # 筛选条件管理
│   │   ├── resume_upload.py    # 简历上传筛选
│   │   ├── talent_query.py     # 人才信息查询
│   │   └── analysis.py         # 数据分析
│   └── components/             # 公共组件
│       ├── sidebar.py
│       └── charts.py
├── tests/                      # 测试
│   ├── conftest.py             # pytest配置和fixtures
│   ├── test_data/              # 测试数据
│   │   └── resumes/            # 测试简历
│   │       ├── AI求职简历-张志伟.pdf
│   │       ├── 大数据开发1.docx
│   │       ├── 李佳阳简历.pdf
│   │       ├── 蔡文军-个人简历.docx
│   │       ├── 鄢天生简历.pdf
│   │       └── 陈帆帆_数据开发.pdf
│   ├── unit/                   # 单元测试
│   │   ├── test_parsers.py
│   │   ├── test_models.py
│   │   └── test_utils.py
│   ├── integration/            # 集成测试
│   │   ├── test_api.py
│   │   ├── test_storage.py
│   │   └── test_workflow.py
│   ├── e2e/                    # 端对端测试
│   │   └── test_resume_flow.py
│   └── regression/             # 回归测试
│       └── test_all.py
├── pyproject.toml              # 项目配置
└── .env                        # 环境变量
```

***

## 四、数据库设计

### 4.1 ER 图

```
┌──────────────────┐
│ screening_condition│
├──────────────────┤
│ id (PK)          │
│ name             │
│ conditions (JSON)│
│ status           │
└──────────────────┘

┌──────────────────┐
│   talent_info    │
├──────────────────┤
│ id (PK)          │
│ name             │
│ phone (加密)     │
│ email (加密)     │
│ education_level  │
│ school           │
│ major            │
│ skills (JSON)    │
│ photo_url        │
│ resume_text      │
│ screening_status │
│ screening_date   │
└──────────────────┘
```

### 4.2 索引设计

```sql
-- 人才信息表索引
CREATE INDEX idx_talent_name ON talent_info(name);
CREATE INDEX idx_talent_school ON talent_info(school);
CREATE INDEX idx_talent_major ON talent_info(major);
CREATE INDEX idx_talent_education ON talent_info(education_level);
CREATE INDEX idx_talent_screening_status ON talent_info(screening_status);
CREATE INDEX idx_talent_screening_date ON talent_info(screening_date);

-- 筛选条件表索引
CREATE INDEX idx_condition_status ON screening_condition(status);
```

### 4.3 通用响应模型

```python
# src/schemas/common.py
from typing import Generic, TypeVar
from pydantic import BaseModel

T = TypeVar("T")

class PaginatedResponse(BaseModel, Generic[T]):
    """分页响应模型"""
    items: list[T]
    total: int
    page: int
    page_size: int
    total_pages: int

class APIResponse(BaseModel, Generic[T]):
    """统一API响应模型"""
    success: bool = True
    message: str = "操作成功"
    data: T | None = None
```

***

## 五、API 接口清单

### 5.1 筛选条件管理

| 方法     | 路径                      | 说明              |
| ------ | ----------------------- | --------------- |
| POST   | /api/v1/conditions      | 新增筛选条件          |
| PUT    | /api/v1/conditions/{id} | 修改筛选条件          |
| DELETE | /api/v1/conditions/{id} | 逻辑删除            |
| GET    | /api/v1/conditions      | 分页查询（支持多状态、多条件） |

### 5.2 人才管理（合并简历、向量功能）

| 方法   | 路径                              | 说明                 |
| ---- | ------------------------------- | ------------------ |
| POST | /api/v1/talents/upload-screen   | 上传简历并执行智能筛选        |
| GET  | /api/v1/talents                 | 分页查询（按姓名、专业、院校、日期） |
| GET  | /api/v1/talents/{id}            | 获取人才详情             |
| POST | /api/v1/talents/{id}/vectorize  | 向量化指定人才            |
| POST | /api/v1/talents/batch-vectorize | 批量向量化              |

### 5.3 数据分析

| 方法   | 路径                          | 说明                   |
| ---- | --------------------------- | -------------------- |
| POST | /api/v1/analysis/query      | RAG智能查询（支持按学校、学历、专业） |
| GET  | /api/v1/analysis/statistics | 统计数据                 |

**总计：11 个核心 API 接口**

***

## 六、前端页面设计（Streamlit）

### 6.1 页面结构

| 页面     | 文件                 | 功能              |
| ------ | ------------------ | --------------- |
| 首页     | `app.py`           | 系统概览、快捷入口       |
| 筛选条件管理 | `conditions.py`    | 新增/修改/删除/查询筛选条件 |
| 简历上传筛选 | `resume_upload.py` | 上传PDF、执行智能筛选    |
| 人才信息查询 | `talent_query.py`  | 分页查询、多条件搜索      |
| 数据分析   | `analysis.py`      | RAG查询、统计图表      |

### 6.2 页面功能详情

#### 首页

* 系统统计数据展示

* 最近筛选记录

* 快捷操作入口

#### 筛选条件管理

* 条件列表展示（分页）

* 新增/编辑条件表单

* 逻辑删除确认

* 多状态筛选

#### 简历上传筛选

* PDF文件上传组件

* 筛选条件选择

* 筛选进度展示

* 结果预览

#### 人才信息查询

* 数据表格展示

* 多条件筛选（姓名、专业、院校、选拔日期）

* 详情查看弹窗

* 照片展示

* 选拔日期范围筛选

#### 数据分析

* RAG智能问答界面

* 按学校/学历/专业统计图表

* 数据看板（人才分布、筛选趋势）

* 数据导出功能（CSV/Excel）

***

## 七、依赖清单

```toml
[project]
dependencies = [
    "fastapi>=0.120.0",
    "uvicorn[standard]>=0.30.0",
    "langchain>=1.2.0",
    "langchain-core>=0.3.0",
    "langchain-community>=0.3.0",
    "langgraph>=1.0.0",
    "pydantic>=2.0.0",
    "pydantic-settings>=2.0.0",
    "sqlalchemy>=2.0.0",
    "aiomysql>=0.2.0",
    "pymupdf>=1.24.0",
    "python-docx>=1.1.0",
    "minio>=7.2.0",
    "chromadb>=0.5.0",
    "redis>=5.0.0",
    "streamlit>=1.30.0",
    "plotly>=5.0.0",
    "python-multipart>=0.0.9",
    "cryptography>=42.0.0",
    "httpx>=0.27.0",
    "loguru>=0.7.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "pytest-cov>=5.0.0",
    "ruff>=0.6.0",
    "basedpyright>=0.7.0",
]
```

***

## 八、外部服务配置

### 8.1 LLM 服务

| 服务        | 用途                   | 配置                                        |
| --------- | -------------------- | ----------------------------------------- |
| DeepSeek  | 实体提取、条件筛选、RAG查询      | `DS_API_KEY`, `DS_BASE_URL`               |
| DashScope | Embedding向量化、备用LLM服务 | `DASHSCOPE_API_KEY`, `DASHSCOPE_BASE_URL` |

### 8.2 MinIO 对象存储

| 配置项        | 值                            |
| ---------- | ---------------------------- |
| Endpoint   | `39.108.222.138:9000`        |
| Console    | `http://39.108.222.138:9001` |
| Access Key | `root`                       |
| Secret Key | `123456`                     |
| Bucket     | `resume-images`              |
| Secure     | `false`                      |

### 8.3 MySQL 数据库

| 配置项      | 值                  |
| -------- | ------------------ |
| Host     | `39.108.222.138`   |
| Port     | `3306`             |
| User     | `root`             |
| Password | `123456`           |
| Database | `resume_screening` |

### 8.4 Redis 缓存

| 配置项      | 值                |
| -------- | ---------------- |
| Host     | `39.108.222.138` |
| Port     | `6379`           |
| Password | `123456`         |
| DB       | `0`              |

**用途**:

* 缓存筛选条件配置

* 缓存 LLM 响应结果

* 任务队列状态管理

### 8.5 ChromaDB

| 配置项        | 说明               |
| ---------- | ---------------- |
| 存储方式       | 本地持久化存储          |
| Collection | `talent_resumes` |

***

## 九、实施计划

### Phase 1: 基础架构搭建

* [ ] 项目初始化与依赖配置

* [ ] 数据库模型设计（2张表）

* [ ] MinIO 存储配置与连接测试

* [ ] Redis 缓存配置与连接测试

* [ ] ChromaDB 初始化

* [ ] FastAPI 基础框架搭建

### Phase 2: 核心模块开发

* [ ] 筛选条件管理模块

* [ ] 简历解析模块

* [ ] LangGraph 工作流实现（4节点）

* [ ] 智能信息提取模块

### Phase 3: 向量与检索

* [ ] 向量化存储实现

* [ ] RAG 查询实现

* [ ] 多维度分析接口

### Phase 4: 前端开发（Streamlit）

* [ ] 主应用框架搭建

* [ ] 筛选条件管理页面

* [ ] 简历上传筛选页面

* [ ] 人才信息查询页面

* [ ] 数据分析可视化页面

### Phase 5: 测试与优化

* [ ] 单元测试编写（覆盖率 ≥ 95%）

* [ ] 集成测试编写

* [ ] 端对端测试编写

* [ ] 回归测试配置

* [ ] 性能优化

* [ ] 安全加固

***

## 十、非功能性需求

### 10.1 性能要求

| 指标     | 要求       | 说明      |
| ------ | -------- | ------- |
| 系统响应时间 | ≤ 3秒     | 除大模型调用外 |
| 并发处理能力 | ≥ 50份/分钟 | 简历上传与解析 |
| 向量检索延迟 | ≤ 500ms  | 单次查询    |

### 10.2 安全要求

* **敏感信息加密**: 手机号、邮箱使用 AES 加密存储

* **文件校验**: 上传文件类型、大小限制（PDF/Word，最大10MB）

* **SQL 注入防护**: 使用 ORM 参数化查询

* **API 认证**: API Key 认证（可选，内部系统可关闭）

* **请求限流**: 每IP每分钟最多100次请求

* **CORS 配置**: 仅允许指定域名访问

### 10.3 可扩展性

* 模块化设计，支持功能独立扩展

* 向量数据库支持迁移至 Milvus/Pinecone

* LLM 支持多模型切换（DeepSeek/DashScope）

### 10.4 LLM 接口要求

* **异步调用**: 所有 LLM 调用使用 async/await

* **超时重试**: 最大重试 3 次，超时时间 30 秒

* **降级方案**: DeepSeek 失败时自动切换 DashScope

### 10.5 向量数据库要求

* **批量插入**: 支持批量向量化插入，提升效率

* **实时检索**: 查询响应时间 ≤ 500ms

### 10.6 部署要求

* **容器化**: 使用 Docker 容器化部署

* **服务编排**: 使用 docker-compose 编排多服务

* **环境隔离**: 开发/测试/生产环境分离

### 10.7 日志要求

* **日志框架**: 使用 loguru 进行日志记录

* **日志级别**: DEBUG/INFO/WARNING/ERROR/CRITICAL

* **日志格式**: 结构化JSON格式，包含时间戳、模块、级别、消息

* **日志文件**: 按日期轮转，保留30天

* **异常追踪**: 完整的异常堆栈记录

### 10.8 异常处理要求

* **全局异常捕获**: FastAPI 全局异常处理器

* **业务异常**: 自定义业务异常类，明确错误码和消息

* **LLM异常**: 超时、限流、API错误统一处理

* **存储异常**: 数据库、MinIO、Redis连接异常重试机制

* **日志记录**: 所有异常必须记录完整上下文信息

### 10.9 测试要求

* **测试框架**: pytest + pytest-asyncio + pytest-cov

* **代码质量**: ruff 格式化 + basedpyright 类型检查

* **测试覆盖率**: ≥ 95%

* **测试类型**:

  * **单元测试**: 测试单个函数/方法/类的正确性

  * **集成测试**: 测试模块间交互（API + 数据库 + 存储）

  * **端对端测试**: 测试完整业务流程（上传简历 → 筛选 → 入库 → 查询）

  * **回归测试**: 每次代码变更后自动运行全量测试

* **测试报告**: 生成 HTML 覆盖率报告

* **CI集成**: 代码提交自动运行测试

***

## 十一、风险与应对

| 风险          | 影响 | 应对措施              |
| ----------- | -- | ----------------- |
| LLM API 不稳定 | 高  | 实现重试机制、超时处理、双模型备份 |
| PDF 解析失败    | 中  | 错误日志记录、人工审核       |
| 向量库性能瓶颈     | 中  | 批量插入优化            |
| 敏感数据泄露      | 高  | 加密存储、访问控制         |
| MinIO 连接失败  | 中  | 连接池、重试机制          |
| MySQL 连接失败  | 中  | 连接池、重试机制、健康检查     |
| Redis 连接失败  | 低  | 降级处理、直接查询数据库      |

***

## 十二、验收标准

1. **功能完整性**: 五大模块全部实现并通过测试
2. **性能达标**: 响应时间、并发处理满足要求
3. **安全合规**: 敏感数据加密
4. **代码质量**: 通过 ruff 格式化、basedpyright 类型检查
5. **测试覆盖**: 测试覆盖率 ≥ 95%
6. **架构精简**: 代码轻量简洁，无冗余设计

***

## 十三、部署配置

### 13.1 Dockerfile

```dockerfile
FROM python:3.13-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# 安装 uv
RUN pip install uv

# 复制项目文件
COPY pyproject.toml .
COPY src/ ./src/
COPY frontend/ ./frontend/

# 安装依赖
RUN uv pip install --system -e .

# 暴露端口
EXPOSE 8000 8501

# 启动命令
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 13.2 docker-compose.yml

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MYSQL_HOST=mysql
      - MINIO_ENDPOINT=minio:9000
      - REDIS_HOST=redis
    depends_on:
      - mysql
      - minio
      - redis
    volumes:
      - ./chroma_data:/app/chroma_data

  frontend:
    build: .
    ports:
      - "8501:8501"
    command: ["streamlit", "run", "frontend/app.py"]
    depends_on:
      - api

  mysql:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: 123456
      MYSQL_DATABASE: resume_screening
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql

  minio:
    image: minio/minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: root
      MINIO_ROOT_PASSWORD: 123456
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data

  redis:
    image: redis:7-alpine
    command: redis-server --requirepass 123456
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  mysql_data:
  minio_data:
  redis_data:
```

### 13.3 健康检查端点

```python
# src/api/health.py
from fastapi import APIRouter

router = APIRouter()

@router.get("/health")
async def health_check():
    """健康检查端点"""
    return {
        "status": "healthy",
        "services": {
            "mysql": "connected",
            "minio": "connected",
            "redis": "connected",
            "chromadb": "connected"
        }
    }
```

### 13.4 测试配置

```toml
# pyproject.toml 测试配置
[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
asyncio_mode = "auto"
addopts = [
    "-v",
    "--tb=short",
    "--cov=src",
    "--cov-report=html",
    "--cov-report=term-missing",
    "--cov-fail-under=95"
]

[tool.ruff]
line-length = 120
target-version = "py313"
select = ["E", "F", "I", "N", "W", "UP", "B", "C4", "SIM"]

[tool.basedpyright]
pythonVersion = "3.13"
typeCheckingMode = "strict"
reportMissingImports = true
reportMissingTypeStubs = false
```

### 13.5 测试示例

```python
# tests/conftest.py
import pytest
from httpx import AsyncClient
from src.api.main import app

@pytest.fixture
async def client():
    """异步HTTP客户端fixture"""
    async with AsyncClient(app=app, base_url="http://test") as ac:
        yield ac

# tests/unit/test_parsers.py
import pytest
from pathlib import Path
from src.parsers.document_parser import DocumentParser

TEST_DATA_DIR = Path(__file__).parent.parent / "test_data" / "resumes"

class TestDocumentParser:
    """文档解析器单元测试"""
    
    @pytest.mark.asyncio
    async def test_parse_pdf_text(self):
        """测试PDF文本提取"""
        parser = DocumentParser()
        pdf_path = TEST_DATA_DIR / "李佳阳简历.pdf"
        text = await parser.extract_text(pdf_path)
        assert text is not None
        assert len(text) > 0
    
    @pytest.mark.asyncio
    async def test_parse_pdf_images(self):
        """测试PDF图片提取"""
        parser = DocumentParser()
        pdf_path = TEST_DATA_DIR / "AI求职简历-张志伟.pdf"
        images = await parser.extract_images(pdf_path)
        assert isinstance(images, list)
    
    @pytest.mark.asyncio
    async def test_parse_docx_text(self):
        """测试Word文本提取"""
        parser = DocumentParser()
        docx_path = TEST_DATA_DIR / "大数据开发1.docx"
        text = await parser.extract_text(docx_path)
        assert text is not None
        assert len(text) > 0

# tests/integration/test_api.py
import pytest

class TestConditionsAPI:
    """筛选条件API集成测试"""
    
    @pytest.mark.asyncio
    async def test_create_condition(self, client):
        """测试创建筛选条件"""
        response = await client.post("/api/v1/conditions", json={
            "name": "测试条件",
            "conditions": {"skills": ["Python"]}
        })
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_list_conditions(self, client):
        """测试查询筛选条件"""
        response = await client.get("/api/v1/conditions")
        assert response.status_code == 200

# tests/e2e/test_resume_flow.py
import pytest
from pathlib import Path

TEST_DATA_DIR = Path(__file__).parent.parent / "test_data" / "resumes"

class TestResumeFlow:
    """简历处理端对端测试"""
    
    @pytest.mark.asyncio
    async def test_full_resume_flow_pdf(self, client):
        """测试完整PDF简历处理流程"""
        pdf_path = TEST_DATA_DIR / "李佳阳简历.pdf"
        with open(pdf_path, "rb") as f:
            response = await client.post(
                "/api/v1/talents/upload-screen",
                files={"file": ("李佳阳简历.pdf", f, "application/pdf")}
            )
        assert response.status_code == 200
        
        response = await client.get("/api/v1/talents")
        assert response.status_code == 200
        data = response.json()
        assert data["total"] > 0
    
    @pytest.mark.asyncio
    async def test_full_resume_flow_docx(self, client):
        """测试完整Word简历处理流程"""
        docx_path = TEST_DATA_DIR / "大数据开发1.docx"
        with open(docx_path, "rb") as f:
            response = await client.post(
                "/api/v1/talents/upload-screen",
                files={"file": ("大数据开发1.docx", f, "application/vnd.openxmlformats-officedocument.wordprocessingml.document")}
            )
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_batch_resume_processing(self, client):
        """测试批量简历处理"""
        resume_files = [
            "AI求职简历-张志伟.pdf",
            "鄢天生简历.pdf",
            "陈帆帆_数据开发.pdf"
        ]
        for filename in resume_files:
            file_path = TEST_DATA_DIR / filename
            with open(file_path, "rb") as f:
                response = await client.post(
                    "/api/v1/talents/upload-screen",
                    files={"file": (filename, f, "application/pdf")}
                )
            assert response.status_code == 200
```

